{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = '''\n",
    "Kratos, the god of war, a figure carved in might,\n",
    "His scars a testament to countless battles, endless fights.\n",
    "Eyes cold as the winter's bite, resolve like stone,\n",
    "A thunder in his voice, a presence of his own.\n",
    "From ashes of his past, he rises like a storm,\n",
    "Haunted by the ghosts he tried to transform.\n",
    "Blades of Chaos swing with deadly grace,\n",
    "An echo of his rage, no foe can face.\n",
    "Yet beneath the armor, a soul cries to be heard,\n",
    "The loss of his family, a silent, whispered word.\n",
    "On a quest for redemption, he journeys through the night,\n",
    "Seeking peace in lands both dark and bright.\n",
    "His path intertwines with fate, with gods and kin,\n",
    "A father and a warrior, a battle within.\n",
    "The journey's long, the road is rough,\n",
    "But Kratos walks on, enduring, never giving up.\n",
    "For in his heart lies love's enduring flame,\n",
    "A father’s hope to guide, to shield, to tame.\n",
    "His son beside him, the story yet unfolds,\n",
    "Kratos, the god of war, with a heart of gold.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = poem.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kratos, the god of war, a figure carved in might,',\n",
       " 'His scars a testament to countless battles, endless fights.',\n",
       " \"Eyes cold as the winter's bite, resolve like stone,\",\n",
       " 'A thunder in his voice, a presence of his own.',\n",
       " 'From ashes of his past, he rises like a storm,',\n",
       " 'Haunted by the ghosts he tried to transform.',\n",
       " 'Blades of Chaos swing with deadly grace,',\n",
       " 'An echo of his rage, no foe can face.',\n",
       " 'Yet beneath the armor, a soul cries to be heard,',\n",
       " 'The loss of his family, a silent, whispered word.',\n",
       " 'On a quest for redemption, he journeys through the night,',\n",
       " 'Seeking peace in lands both dark and bright.',\n",
       " 'His path intertwines with fate, with gods and kin,',\n",
       " 'A father and a warrior, a battle within.',\n",
       " \"The journey's long, the road is rough,\",\n",
       " 'But Kratos walks on, enduring, never giving up.',\n",
       " \"For in his heart lies love's enduring flame,\",\n",
       " 'A father’s hope to guide, to shield, to tame.',\n",
       " 'His son beside him, the story yet unfolds,',\n",
       " 'Kratos, the god of war, with a heart of gold.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[1:]\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kratos the god of war a figure carved in might',\n",
       " 'his scars a testament to countless battles endless fights',\n",
       " 'eyes cold as the winters bite resolve like stone',\n",
       " 'a thunder in his voice a presence of his own',\n",
       " 'from ashes of his past he rises like a storm',\n",
       " 'haunted by the ghosts he tried to transform',\n",
       " 'blades of chaos swing with deadly grace',\n",
       " 'an echo of his rage no foe can face',\n",
       " 'yet beneath the armor a soul cries to be heard',\n",
       " 'the loss of his family a silent whispered word',\n",
       " 'on a quest for redemption he journeys through the night',\n",
       " 'seeking peace in lands both dark and bright',\n",
       " 'his path intertwines with fate with gods and kin',\n",
       " 'a father and a warrior a battle within',\n",
       " 'the journeys long the road is rough',\n",
       " 'but kratos walks on enduring never giving up',\n",
       " 'for in his heart lies loves enduring flame',\n",
       " 'a father’s hope to guide to shield to tame',\n",
       " 'his son beside him the story yet unfolds',\n",
       " 'kratos the god of war with a heart of gold']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    text = ''.join(char for char in text if char not in string.punctuation).lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset = [preprocess(line) for line in lines]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing. text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<NULL>')\n",
    "tokenizer.fit_on_texts(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<NULL>': 1,\n",
       " 'a': 2,\n",
       " 'the': 3,\n",
       " 'his': 4,\n",
       " 'of': 5,\n",
       " 'to': 6,\n",
       " 'in': 7,\n",
       " 'with': 8,\n",
       " 'kratos': 9,\n",
       " 'he': 10,\n",
       " 'and': 11,\n",
       " 'god': 12,\n",
       " 'war': 13,\n",
       " 'like': 14,\n",
       " 'yet': 15,\n",
       " 'on': 16,\n",
       " 'for': 17,\n",
       " 'journeys': 18,\n",
       " 'enduring': 19,\n",
       " 'heart': 20,\n",
       " 'figure': 21,\n",
       " 'carved': 22,\n",
       " 'might': 23,\n",
       " 'scars': 24,\n",
       " 'testament': 25,\n",
       " 'countless': 26,\n",
       " 'battles': 27,\n",
       " 'endless': 28,\n",
       " 'fights': 29,\n",
       " 'eyes': 30,\n",
       " 'cold': 31,\n",
       " 'as': 32,\n",
       " 'winters': 33,\n",
       " 'bite': 34,\n",
       " 'resolve': 35,\n",
       " 'stone': 36,\n",
       " 'thunder': 37,\n",
       " 'voice': 38,\n",
       " 'presence': 39,\n",
       " 'own': 40,\n",
       " 'from': 41,\n",
       " 'ashes': 42,\n",
       " 'past': 43,\n",
       " 'rises': 44,\n",
       " 'storm': 45,\n",
       " 'haunted': 46,\n",
       " 'by': 47,\n",
       " 'ghosts': 48,\n",
       " 'tried': 49,\n",
       " 'transform': 50,\n",
       " 'blades': 51,\n",
       " 'chaos': 52,\n",
       " 'swing': 53,\n",
       " 'deadly': 54,\n",
       " 'grace': 55,\n",
       " 'an': 56,\n",
       " 'echo': 57,\n",
       " 'rage': 58,\n",
       " 'no': 59,\n",
       " 'foe': 60,\n",
       " 'can': 61,\n",
       " 'face': 62,\n",
       " 'beneath': 63,\n",
       " 'armor': 64,\n",
       " 'soul': 65,\n",
       " 'cries': 66,\n",
       " 'be': 67,\n",
       " 'heard': 68,\n",
       " 'loss': 69,\n",
       " 'family': 70,\n",
       " 'silent': 71,\n",
       " 'whispered': 72,\n",
       " 'word': 73,\n",
       " 'quest': 74,\n",
       " 'redemption': 75,\n",
       " 'through': 76,\n",
       " 'night': 77,\n",
       " 'seeking': 78,\n",
       " 'peace': 79,\n",
       " 'lands': 80,\n",
       " 'both': 81,\n",
       " 'dark': 82,\n",
       " 'bright': 83,\n",
       " 'path': 84,\n",
       " 'intertwines': 85,\n",
       " 'fate': 86,\n",
       " 'gods': 87,\n",
       " 'kin': 88,\n",
       " 'father': 89,\n",
       " 'warrior': 90,\n",
       " 'battle': 91,\n",
       " 'within': 92,\n",
       " 'long': 93,\n",
       " 'road': 94,\n",
       " 'is': 95,\n",
       " 'rough': 96,\n",
       " 'but': 97,\n",
       " 'walks': 98,\n",
       " 'never': 99,\n",
       " 'giving': 100,\n",
       " 'up': 101,\n",
       " 'lies': 102,\n",
       " 'loves': 103,\n",
       " 'flame': 104,\n",
       " 'father’s': 105,\n",
       " 'hope': 106,\n",
       " 'guide': 107,\n",
       " 'shield': 108,\n",
       " 'tame': 109,\n",
       " 'son': 110,\n",
       " 'beside': 111,\n",
       " 'him': 112,\n",
       " 'story': 113,\n",
       " 'unfolds': 114,\n",
       " 'gold': 115}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('kratos', 3),\n",
       "             ('the', 10),\n",
       "             ('god', 2),\n",
       "             ('of', 8),\n",
       "             ('war', 2),\n",
       "             ('a', 13),\n",
       "             ('figure', 1),\n",
       "             ('carved', 1),\n",
       "             ('in', 4),\n",
       "             ('might', 1),\n",
       "             ('his', 9),\n",
       "             ('scars', 1),\n",
       "             ('testament', 1),\n",
       "             ('to', 6),\n",
       "             ('countless', 1),\n",
       "             ('battles', 1),\n",
       "             ('endless', 1),\n",
       "             ('fights', 1),\n",
       "             ('eyes', 1),\n",
       "             ('cold', 1),\n",
       "             ('as', 1),\n",
       "             ('winters', 1),\n",
       "             ('bite', 1),\n",
       "             ('resolve', 1),\n",
       "             ('like', 2),\n",
       "             ('stone', 1),\n",
       "             ('thunder', 1),\n",
       "             ('voice', 1),\n",
       "             ('presence', 1),\n",
       "             ('own', 1),\n",
       "             ('from', 1),\n",
       "             ('ashes', 1),\n",
       "             ('past', 1),\n",
       "             ('he', 3),\n",
       "             ('rises', 1),\n",
       "             ('storm', 1),\n",
       "             ('haunted', 1),\n",
       "             ('by', 1),\n",
       "             ('ghosts', 1),\n",
       "             ('tried', 1),\n",
       "             ('transform', 1),\n",
       "             ('blades', 1),\n",
       "             ('chaos', 1),\n",
       "             ('swing', 1),\n",
       "             ('with', 4),\n",
       "             ('deadly', 1),\n",
       "             ('grace', 1),\n",
       "             ('an', 1),\n",
       "             ('echo', 1),\n",
       "             ('rage', 1),\n",
       "             ('no', 1),\n",
       "             ('foe', 1),\n",
       "             ('can', 1),\n",
       "             ('face', 1),\n",
       "             ('yet', 2),\n",
       "             ('beneath', 1),\n",
       "             ('armor', 1),\n",
       "             ('soul', 1),\n",
       "             ('cries', 1),\n",
       "             ('be', 1),\n",
       "             ('heard', 1),\n",
       "             ('loss', 1),\n",
       "             ('family', 1),\n",
       "             ('silent', 1),\n",
       "             ('whispered', 1),\n",
       "             ('word', 1),\n",
       "             ('on', 2),\n",
       "             ('quest', 1),\n",
       "             ('for', 2),\n",
       "             ('redemption', 1),\n",
       "             ('journeys', 2),\n",
       "             ('through', 1),\n",
       "             ('night', 1),\n",
       "             ('seeking', 1),\n",
       "             ('peace', 1),\n",
       "             ('lands', 1),\n",
       "             ('both', 1),\n",
       "             ('dark', 1),\n",
       "             ('and', 3),\n",
       "             ('bright', 1),\n",
       "             ('path', 1),\n",
       "             ('intertwines', 1),\n",
       "             ('fate', 1),\n",
       "             ('gods', 1),\n",
       "             ('kin', 1),\n",
       "             ('father', 1),\n",
       "             ('warrior', 1),\n",
       "             ('battle', 1),\n",
       "             ('within', 1),\n",
       "             ('long', 1),\n",
       "             ('road', 1),\n",
       "             ('is', 1),\n",
       "             ('rough', 1),\n",
       "             ('but', 1),\n",
       "             ('walks', 1),\n",
       "             ('enduring', 2),\n",
       "             ('never', 1),\n",
       "             ('giving', 1),\n",
       "             ('up', 1),\n",
       "             ('heart', 2),\n",
       "             ('lies', 1),\n",
       "             ('loves', 1),\n",
       "             ('flame', 1),\n",
       "             ('father’s', 1),\n",
       "             ('hope', 1),\n",
       "             ('guide', 1),\n",
       "             ('shield', 1),\n",
       "             ('tame', 1),\n",
       "             ('son', 1),\n",
       "             ('beside', 1),\n",
       "             ('him', 1),\n",
       "             ('story', 1),\n",
       "             ('unfolds', 1),\n",
       "             ('gold', 1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = [tokenizer.texts_to_sequences([line]) for line in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 3, 12, 5, 13, 2, 21, 22, 7, 23]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 3],\n",
       " [9, 3, 12],\n",
       " [9, 3, 12, 5],\n",
       " [9, 3, 12, 5, 13],\n",
       " [9, 3, 12, 5, 13, 2],\n",
       " [9, 3, 12, 5, 13, 2, 21],\n",
       " [9, 3, 12, 5, 13, 2, 21, 22],\n",
       " [9, 3, 12, 5, 13, 2, 21, 22, 7],\n",
       " [9, 3, 12, 5, 13, 2, 21, 22, 7, 23],\n",
       " [9, 3, 12, 5, 13, 2, 21, 22, 7, 23],\n",
       " [4, 24],\n",
       " [4, 24, 2],\n",
       " [4, 24, 2, 25],\n",
       " [4, 24, 2, 25, 6],\n",
       " [4, 24, 2, 25, 6, 26],\n",
       " [4, 24, 2, 25, 6, 26, 27],\n",
       " [4, 24, 2, 25, 6, 26, 27, 28],\n",
       " [4, 24, 2, 25, 6, 26, 27, 28, 29],\n",
       " [4, 24, 2, 25, 6, 26, 27, 28, 29],\n",
       " [30, 31],\n",
       " [30, 31, 32],\n",
       " [30, 31, 32, 3],\n",
       " [30, 31, 32, 3, 33],\n",
       " [30, 31, 32, 3, 33, 34],\n",
       " [30, 31, 32, 3, 33, 34, 35],\n",
       " [30, 31, 32, 3, 33, 34, 35, 14],\n",
       " [30, 31, 32, 3, 33, 34, 35, 14, 36],\n",
       " [30, 31, 32, 3, 33, 34, 35, 14, 36],\n",
       " [2, 37],\n",
       " [2, 37, 7],\n",
       " [2, 37, 7, 4],\n",
       " [2, 37, 7, 4, 38],\n",
       " [2, 37, 7, 4, 38, 2],\n",
       " [2, 37, 7, 4, 38, 2, 39],\n",
       " [2, 37, 7, 4, 38, 2, 39, 5],\n",
       " [2, 37, 7, 4, 38, 2, 39, 5, 4],\n",
       " [2, 37, 7, 4, 38, 2, 39, 5, 4, 40],\n",
       " [2, 37, 7, 4, 38, 2, 39, 5, 4, 40],\n",
       " [41, 42],\n",
       " [41, 42, 5],\n",
       " [41, 42, 5, 4],\n",
       " [41, 42, 5, 4, 43],\n",
       " [41, 42, 5, 4, 43, 10],\n",
       " [41, 42, 5, 4, 43, 10, 44],\n",
       " [41, 42, 5, 4, 43, 10, 44, 14],\n",
       " [41, 42, 5, 4, 43, 10, 44, 14, 2],\n",
       " [41, 42, 5, 4, 43, 10, 44, 14, 2, 45],\n",
       " [41, 42, 5, 4, 43, 10, 44, 14, 2, 45],\n",
       " [46, 47],\n",
       " [46, 47, 3],\n",
       " [46, 47, 3, 48],\n",
       " [46, 47, 3, 48, 10],\n",
       " [46, 47, 3, 48, 10, 49],\n",
       " [46, 47, 3, 48, 10, 49, 6],\n",
       " [46, 47, 3, 48, 10, 49, 6, 50],\n",
       " [46, 47, 3, 48, 10, 49, 6, 50],\n",
       " [51, 5],\n",
       " [51, 5, 52],\n",
       " [51, 5, 52, 53],\n",
       " [51, 5, 52, 53, 8],\n",
       " [51, 5, 52, 53, 8, 54],\n",
       " [51, 5, 52, 53, 8, 54, 55],\n",
       " [51, 5, 52, 53, 8, 54, 55],\n",
       " [56, 57],\n",
       " [56, 57, 5],\n",
       " [56, 57, 5, 4],\n",
       " [56, 57, 5, 4, 58],\n",
       " [56, 57, 5, 4, 58, 59],\n",
       " [56, 57, 5, 4, 58, 59, 60],\n",
       " [56, 57, 5, 4, 58, 59, 60, 61],\n",
       " [56, 57, 5, 4, 58, 59, 60, 61, 62],\n",
       " [56, 57, 5, 4, 58, 59, 60, 61, 62],\n",
       " [15, 63],\n",
       " [15, 63, 3],\n",
       " [15, 63, 3, 64],\n",
       " [15, 63, 3, 64, 2],\n",
       " [15, 63, 3, 64, 2, 65],\n",
       " [15, 63, 3, 64, 2, 65, 66],\n",
       " [15, 63, 3, 64, 2, 65, 66, 6],\n",
       " [15, 63, 3, 64, 2, 65, 66, 6, 67],\n",
       " [15, 63, 3, 64, 2, 65, 66, 6, 67, 68],\n",
       " [15, 63, 3, 64, 2, 65, 66, 6, 67, 68],\n",
       " [3, 69],\n",
       " [3, 69, 5],\n",
       " [3, 69, 5, 4],\n",
       " [3, 69, 5, 4, 70],\n",
       " [3, 69, 5, 4, 70, 2],\n",
       " [3, 69, 5, 4, 70, 2, 71],\n",
       " [3, 69, 5, 4, 70, 2, 71, 72],\n",
       " [3, 69, 5, 4, 70, 2, 71, 72, 73],\n",
       " [3, 69, 5, 4, 70, 2, 71, 72, 73],\n",
       " [16, 2],\n",
       " [16, 2, 74],\n",
       " [16, 2, 74, 17],\n",
       " [16, 2, 74, 17, 75],\n",
       " [16, 2, 74, 17, 75, 10],\n",
       " [16, 2, 74, 17, 75, 10, 18],\n",
       " [16, 2, 74, 17, 75, 10, 18, 76],\n",
       " [16, 2, 74, 17, 75, 10, 18, 76, 3],\n",
       " [16, 2, 74, 17, 75, 10, 18, 76, 3, 77],\n",
       " [16, 2, 74, 17, 75, 10, 18, 76, 3, 77],\n",
       " [78, 79],\n",
       " [78, 79, 7],\n",
       " [78, 79, 7, 80],\n",
       " [78, 79, 7, 80, 81],\n",
       " [78, 79, 7, 80, 81, 82],\n",
       " [78, 79, 7, 80, 81, 82, 11],\n",
       " [78, 79, 7, 80, 81, 82, 11, 83],\n",
       " [78, 79, 7, 80, 81, 82, 11, 83],\n",
       " [4, 84],\n",
       " [4, 84, 85],\n",
       " [4, 84, 85, 8],\n",
       " [4, 84, 85, 8, 86],\n",
       " [4, 84, 85, 8, 86, 8],\n",
       " [4, 84, 85, 8, 86, 8, 87],\n",
       " [4, 84, 85, 8, 86, 8, 87, 11],\n",
       " [4, 84, 85, 8, 86, 8, 87, 11, 88],\n",
       " [4, 84, 85, 8, 86, 8, 87, 11, 88],\n",
       " [2, 89],\n",
       " [2, 89, 11],\n",
       " [2, 89, 11, 2],\n",
       " [2, 89, 11, 2, 90],\n",
       " [2, 89, 11, 2, 90, 2],\n",
       " [2, 89, 11, 2, 90, 2, 91],\n",
       " [2, 89, 11, 2, 90, 2, 91, 92],\n",
       " [2, 89, 11, 2, 90, 2, 91, 92],\n",
       " [3, 18],\n",
       " [3, 18, 93],\n",
       " [3, 18, 93, 3],\n",
       " [3, 18, 93, 3, 94],\n",
       " [3, 18, 93, 3, 94, 95],\n",
       " [3, 18, 93, 3, 94, 95, 96],\n",
       " [3, 18, 93, 3, 94, 95, 96],\n",
       " [97, 9],\n",
       " [97, 9, 98],\n",
       " [97, 9, 98, 16],\n",
       " [97, 9, 98, 16, 19],\n",
       " [97, 9, 98, 16, 19, 99],\n",
       " [97, 9, 98, 16, 19, 99, 100],\n",
       " [97, 9, 98, 16, 19, 99, 100, 101],\n",
       " [97, 9, 98, 16, 19, 99, 100, 101],\n",
       " [17, 7],\n",
       " [17, 7, 4],\n",
       " [17, 7, 4, 20],\n",
       " [17, 7, 4, 20, 102],\n",
       " [17, 7, 4, 20, 102, 103],\n",
       " [17, 7, 4, 20, 102, 103, 19],\n",
       " [17, 7, 4, 20, 102, 103, 19, 104],\n",
       " [17, 7, 4, 20, 102, 103, 19, 104],\n",
       " [2, 105],\n",
       " [2, 105, 106],\n",
       " [2, 105, 106, 6],\n",
       " [2, 105, 106, 6, 107],\n",
       " [2, 105, 106, 6, 107, 6],\n",
       " [2, 105, 106, 6, 107, 6, 108],\n",
       " [2, 105, 106, 6, 107, 6, 108, 6],\n",
       " [2, 105, 106, 6, 107, 6, 108, 6, 109],\n",
       " [2, 105, 106, 6, 107, 6, 108, 6, 109],\n",
       " [4, 110],\n",
       " [4, 110, 111],\n",
       " [4, 110, 111, 112],\n",
       " [4, 110, 111, 112, 3],\n",
       " [4, 110, 111, 112, 3, 113],\n",
       " [4, 110, 111, 112, 3, 113, 15],\n",
       " [4, 110, 111, 112, 3, 113, 15, 114],\n",
       " [4, 110, 111, 112, 3, 113, 15, 114],\n",
       " [9, 3],\n",
       " [9, 3, 12],\n",
       " [9, 3, 12, 5],\n",
       " [9, 3, 12, 5, 13],\n",
       " [9, 3, 12, 5, 13, 8],\n",
       " [9, 3, 12, 5, 13, 8, 2],\n",
       " [9, 3, 12, 5, 13, 8, 2, 20],\n",
       " [9, 3, 12, 5, 13, 8, 2, 20, 5],\n",
       " [9, 3, 12, 5, 13, 8, 2, 20, 5, 115],\n",
       " [9, 3, 12, 5, 13, 8, 2, 20, 5, 115]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sequences = []\n",
    "\n",
    "for sequence in tokenized_dataset:\n",
    "    for i, token in enumerate(sequence[0]):\n",
    "        ngram_sequence = sequence[0][0:i+2]\n",
    "        inp_sequences.append(ngram_sequence)\n",
    "inp_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def generate_padded_dataset(inp_sequences):\n",
    "    max_len = max([len(x) for x in inp_sequences])\n",
    "    padded_sequences = np.array(pad_sequences(inp_sequences,max_len, padding = 'pre'))\n",
    "\n",
    "    predictors, labels = padded_sequences[:,:-1], padded_sequences[:,-1]\n",
    "    labels = to_categorical(labels, num_classes=len(tokenizer.word_index) + 1)\n",
    "\n",
    "    return padded_sequences, predictors, labels\n",
    "\n",
    "padded_sequences, predictors, labels = generate_padded_dataset(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arcan\\Desktop\\CodeStuff\\Sem 6\\NLP\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "\n",
    "max_len = max([len(x) for x in inp_sequences])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "def create_model(max_len, total_words):\n",
    "    input_length = max_len - 1\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(total_words,512, input_length=input_length))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(total_words,activation='softmax'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model(max_len, total_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2205f49a8d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(predictors, labels, epochs=100, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, num_words, model, max_len):\n",
    "    for _ in range(num_words):\n",
    "        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        padded_tokens = pad_sequences([tokens], maxlen=max_len -1, padding='pre')\n",
    "        predicted = model.predict(padded_tokens, verbose = 0)\n",
    "\n",
    "        position = np.argmax(predicted[0])\n",
    "\n",
    "        output = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == position:\n",
    "                output = word\n",
    "                break\n",
    "        \n",
    "        seed_text += \" \" + output\n",
    "    \n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'His Scars A Testament To Countless Battles Endless Fights Fights'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('His scars', 8, model, max_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
